---
title: "Monet Carlo Integration"
author: "Jinyi Chen"
date: "2020/11/14"
output: pdf_document
---

# Exercise 7.5.1

## (a)

Consider $g(x)$ has the density fucntion 
$$g(x) =\frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}$$.
```{r}
h <- function(x) {x^2}
df <- function(x) {(x^2 * exp(-((x-2)^2)/2))/(5*sqrt(2*pi))}

g <- function(x) {dnorm(x)}
rg <- function(n) {rnorm(n)}

isAppr <- function(n, h, df, g, rg){
  x <- rg(n)
  mean(h(x) * df(x)/g(x))
}

mysummary <- function(nrep, n, h, df, g, rg){
  sim <- replicate(nrep,isAppr(n, h, df, g, rg))
  c(Expection = mean(sim), Variance = var(sim))
}

mysummary(100,1000, h, df, g, rg)
mysummary(100,10000, h, df, g, rg)
mysummary(100,50000, h, df, g, rg)

```

## (b)

Note that $h(x) = x^2$, a better $g(x)$ can be chosen to be $g(x) \propto x^4 \exp(-\frac{(x-2)^2}{2})$.
One also have $\int_{-\infty}^{+\infty}g(x)\text{d}x=1$, that is 
$$
g(x) = \frac{x^4 \exp(-\frac{(x-2)^2}{2})}
{\int_{-\infty}^{+\infty}x^4 \exp(-\frac{(x-2)^2}{2})\text{d}x} .
$$
Choose $p(x) = $

It is easy to know that 
$$
E^{N(2,1)}(X^4) = {\int_{-\infty}^{+\infty} \frac{x^4}{\sqrt{2\pi}} \exp(-\frac{(x-2)^2}{2})\text{d}x} 
$$
$$
E^{N(2,1)}(X^4)=E^{N(0,1)}[(Z+2)^4]=E(Z^4)+4E(Z^3)+6E(Z^2)+4E(Z)+16=3+0+6+0+16=25.
$$
We have 
$$g(x) = \frac{1}{25\sqrt{2\pi}} x^4 \exp(-\frac{(x-2)^2}{2}).$$
Since $2x-5 \leq (x-2)^2$, we can write $\exp(-\frac{(x-2)^2}{2}) \leq \exp(-\frac{2x-5}{2})$ and $g(x) \leq x^4\exp(-x)$. This inequality suggests we can use rejection sampling method with $Gamma(5,2)$ to generate a sample depend on $g(x)$.


```{r}
g1 <- function(x){
  dgamma(x, shape = 5, scale = 2)
}
rg1 <- function(n){
  rgamma(n, shape = 5, scale = 2)
}


# Importance sampling function

isAppr <- function(n, h, df, g, rg){
  x <- rg(n)
  mean(h(x) * df(x) / g(x))
}

mysummary <- function(nrep, n, h, df, g, rg){
  sim <- replicate(nrep,isAppr(n, h, df, g, rg))
  c(Expection = mean(sim), Variance = var(sim))
}

```

## (c)

```{r}
mysummary(100,1000, h, df, g1, rg1)
mysummary(100,10000, h, df, g1, rg1)
mysummary(100,50000, h, df, g1, rg1)
```

## (d)
The variances of the second method are closer to 0 comparing with those of first method. 




# Exercis 7.5.2

## (a)

One has 
$$
S(T) = S(0)\exp\{(r-\frac{1}{2}\sigma^2)T+ \sigma W(T)\}
$$
where $W(T) = \sqrt{T}Z$ and $Z \sim N(0,1)$.
Function `St_path` is given below to sample the path of $S(t)$.
```{r}
s0 <- 1
r <- 0.05
n <- 12


St_path <- function(s0 = 1, n = 12, t, sigma){
  t_path <- seq(0, t, length.out = n)
  delta <- t/n
  z <- rnorm(1, mean = 0, sd = 1)
  St_path <- vector()
  St_path[1] <- s0 * exp((0.05 - sigma^2/2)*delta + sigma*sqrt(delta)*z)
  for (i in 2:n) {
    z <- rnorm(1, mean = 0, sd = 1)
    St_path[i] <- St_path[i-1] * exp((0.05 - sigma^2/2)*delta + sigma*sqrt(delta)*z)
  }
  return(St_path)
}

```

## (b)

Use the following functions to calculate $S(T), P_A, P_E, P_G$ and their correlation coefficients.
```{r}
ST <- function(St){St[length(St)]}

PA <- function(St, t, K){
  SA <- mean(St)
  exp(- .05 * t) * ifelse(SA-K > 0, SA-K, 0)
}


PE <- function(St,t, K){
  ST <- St[12]
  exp(- .05 * t) * ifelse(ST-K > 0, ST-K, 0)
}

PG <- function(St, t, K){
  SG <- exp(mean(log(St)))
  exp(- .05 * t) * ifelse(SG-K > 0, SG-K, 0)
}

mysummary <- function(s0 = 1, n = 12, t, sigma, K){
  St <- St_path(s0 = s0, n = n, t = t, sigma = sigma)
  c("ST" = ST(St),
    "PA" = PA(St, t, K),
    "PE" = PE(St, t, K),
    "PE" = PG(St, t, K))
}

summaryall <- function(nrep, s0 = 1, n = 12, t, sigma, K){
  sim <- replicate(nrep,
                   mysummary(s0 = s0, n = n, t = t,
                              sigma = sigma, K = K))
  cor_PA_ST <- cor(sim[1,],sim[2,])
  cor_PA_PE <- cor(sim[3,],sim[2,])
  cor_PA_PG <- cor(sim[4,],sim[2,])
  return(c(cor_PA_ST, cor_PA_PE, cor_PA_PG))
}

```

Then we calculate correlation coefficients between $S(T),\ P_A,\ P_E,\ P_G$.

```{r}
nrep = 5000
sigma = 0.5
t = 1
K = c(1.1, 1.2, 1.3, 1.4, 1.5)

cor_K <- sapply(K, function(K){
  summaryall(nrep, s0 = 1, n = 12, t, sigma, K)
})

```
Plot the coefficients.
```{r}
plot(K, cor_K[1,], type = 'l', ylab = "Correlation coefficient",
     main = "Correlation coefficient between PA and S(T)")
plot(K, cor_K[2,], type = 'l', ylab = "Correlation coefficient",
     main = "Correlation coefficient between PA and PE")
plot(K, cor_K[3,], type = 'l', ylab = "Correlation coefficient",
     main = "Correlation coefficient between PA and PG")
```

The correlation coefficients decrease with K increasing.

## (c)

```{r}
t <- 1
K <- 1.5
sigma <- c(2:5)/10
nrep <- 5000

cor_sigma <- sapply(sigma, function(sigma){
  summaryall(nrep, s0 = 1, n = 12, t, sigma, K)
})

plot(sigma, cor_sigma[1,], type = 'l', ylab = "Correlation coefficient",
     main = "Correlation coefficient between PA and S(T)")
plot(sigma, cor_sigma[2,], type = 'l', ylab = "Correlation coefficient",
     main = "Correlation coefficient between PA and PE")
plot(sigma, cor_sigma[3,], type = 'l', ylab = "Correlation coefficient",
     main = "Correlation coefficient between PA and PG")

```

The correlation coefficients increase with $\sigma$ increasing.

## (d)

```{r}
t <- c(0.4,0.7,1,1.3,1.6)
K <- 1.5
sigma <- 0.5
nrep <- 5000

set.seed(100)
cor_t <- sapply(t, function(t){
  summaryall(nrep, s0 = 1, n = 12, t, sigma, K)
})

plot(t, cor_t[1,], type = 'l', ylab = "Correlation coefficient",
     main = "Correlation coefficient between PA and S(T)")
plot(t, cor_t[2,], type = 'l', ylab = "Correlation coefficient",
     main = "Correlation coefficient between PA and PE")
plot(t, cor_t[3,], type = 'l', ylab = "Correlation coefficient",
     main = "Correlation coefficient between PA and PG")

```
The correlation coefficients increase with T increasing.


## (e)

```{r}
s0 <-1
n <- 12
sigma <- 0.4
t <- 1
K <- 1.5

P_A <- replicate(nrep,
                 mysummary(s0 = s0, n = n, t = t,
                           sigma = sigma, K = K))[2,]
# use as ture theta
PG_true <- replicate(nrep,
                     mysummary(s0 = s0, n = 100, t = t,
                               sigma = sigma, K = K))[4,]

PA_control <- function(nrep, t, sigma, K, P_A, theta_true){
  theta <- replicate(nrep,
                     mysummary(s0 = s0, n = n, t = t,
                               sigma = sigma, K = K))[4,]
  theta_h <- mean(theta)
  b <- cov(P_A, theta)/var(theta)
  mean(P_A) - b * (theta_h - theta_true)
}

P_A_control <- PA_control(nrep = 5000, t, sigma, K, P_A, PG_true)

data.frame("SD without control" = sd(P_A),
           "SD with contorl" = sd(P_A_control))
```

The MC estimator with control variate has a smaller standard error.